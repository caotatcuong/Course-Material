{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"Untitled.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"H9agXaU2aaq-"},"source":["[Dataset](https://www.kaggle.com/c/titanic)"]},{"cell_type":"code","metadata":{"id":"E3xRbRhDaarF"},"source":["from pyspark.sql import SparkSession\n","import pyspark.sql.functions as F\n","from pyspark.ml import Transformer, Estimator\n","from pyspark.ml import Pipeline\n","from pyspark.ml.feature import Imputer, OneHotEncoder, StringIndexer, VectorAssembler\n","\n","from pyspark.ml.classification import RandomForestClassifier\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator as BCE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HFHvqTSgaarG"},"source":["#Sets the Spark master URL to connect to \"spark://master:7077\" to run on a Spark standalone cluster.\n","spark = SparkSession.builder.master(\"spark://cuong-Vostro-3578:7077\").appName(\"Data preprocessing\").getOrCreate()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kC6dEpsjaarH"},"source":["# Read data"]},{"cell_type":"code","metadata":{"id":"yOf8jAJKaarH"},"source":["df = spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(\"Data/titanic.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"71V29xzAaarH"},"source":["# Basic exploration"]},{"cell_type":"code","metadata":{"id":"_kcY4lvBaarH","outputId":"25bce381-83c0-4090-ffc8-276c9146d418"},"source":["df.show(5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n","|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n","+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n","|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n","|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n","|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n","|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n","|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n","+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n","only showing top 5 rows\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DQqN_ltuaarI"},"source":["## Shape of data"]},{"cell_type":"code","metadata":{"id":"Wge46cftaarJ","outputId":"e7af79b2-9bdd-4ad1-d04d-f005adc07d8e"},"source":["print((df.count(), len(df.columns)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(891, 12)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0yfWWql8aarJ"},"source":["## Data description"]},{"cell_type":"markdown","metadata":{"id":"811iXIaUaarJ"},"source":["| Variable    | Definition  | Key |\n","| ----------- | ----------- |     |\n","| survival    | Survival    |   0 = No, 1 = Yes  |\n","| pclass      | Ticket class|1 = 1st, 2 = 2nd, 3 = 3rd|\n","| sex         | Sex         |     |\n","| Age         | Age in years|     |\n","| sibsp   | # of siblings / spouses aboard the Titanic|     |\n","| parch   | # of parents / children aboard the Titanic|     |\n","| ticket         | Ticket number\t         |     |\n","| fare         | Passenger fare\t         |     |\n","| cabin         | Cabin number\t         |     |\n","| embarked         | Port of Embarkation|C = Cherbourg, Q = Queenstown, S = Southampton|"]},{"cell_type":"markdown","metadata":{"id":"5celp2lpaarK"},"source":["## Check duplicate"]},{"cell_type":"code","metadata":{"id":"daDCF05xaarK","outputId":"7e2cf711-e4e0-4fbe-f303-181ff2a45ad2"},"source":["df.groupBy(df.columns)\\\n","    .count()\\\n","    .where(F.col('count') > 1)\\\n","    .select(F.sum('count'))\\\n","    .show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+----------+\n","|sum(count)|\n","+----------+\n","|      null|\n","+----------+\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bhNrR2v7aarK"},"source":["## Check missing value"]},{"cell_type":"code","metadata":{"id":"1RaB04ddaarL","outputId":"3fe51004-90d5-4822-fd64-b512f16ee3e4"},"source":["df.select([F.count(F.when(F.isnull(c), c)).alias(c) for c in df.columns]).show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n","|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n","+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n","|          0|       0|     0|   0|  0|177|    0|    0|     0|   0|  687|       2|\n","+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jiKnxZbEaarL"},"source":["## Type of columns"]},{"cell_type":"code","metadata":{"id":"3gyT-udVaarL","outputId":"1d26ce57-84b9-4086-a6aa-c4e9af03f2a6"},"source":["df.dtypes"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('PassengerId', 'int'),\n"," ('Survived', 'int'),\n"," ('Pclass', 'int'),\n"," ('Name', 'string'),\n"," ('Sex', 'string'),\n"," ('Age', 'double'),\n"," ('SibSp', 'int'),\n"," ('Parch', 'int'),\n"," ('Ticket', 'string'),\n"," ('Fare', 'double'),\n"," ('Cabin', 'string'),\n"," ('Embarked', 'string')]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"yAGyntB2aarM"},"source":["## Summary of numeric columns"]},{"cell_type":"code","metadata":{"id":"9u79ZqhiaarM","outputId":"9a3b66da-40fb-42fa-8555-ee0074340fcb"},"source":["columnNumeric = list(set([item[0] for item in df.dtypes if item[1].startswith(('int', 'double'))]) - set('Survived'))\n","df.select(columnNumeric).summary(\"count\", \"min\", \"25%\", \"50%\", \"75%\", \"max\").show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+-------+----+------+-----+--------+-----+--------+-----------+\n","|summary| Age|Pclass|SibSp|Survived|Parch|    Fare|PassengerId|\n","+-------+----+------+-----+--------+-----+--------+-----------+\n","|  count| 714|   891|  891|     891|  891|     891|        891|\n","|    min|0.42|     1|    0|       0|    0|     0.0|          1|\n","|    25%|20.0|     2|    0|       0|    0|  7.8958|        223|\n","|    50%|28.0|     3|    0|       0|    0| 14.4542|        446|\n","|    75%|38.0|     3|    1|       1|    0|    31.0|        669|\n","|    max|80.0|     3|    8|       1|    6|512.3292|        891|\n","+-------+----+------+-----+--------+-----+--------+-----------+\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qCaIXFKQaarM"},"source":["## Count distinct values of categorical columns"]},{"cell_type":"code","metadata":{"id":"sDlZFm4xaarM","outputId":"912e7698-cc44-44d9-9dc7-85ba3741d9e7"},"source":["columnCat = [item[0] for item in df.dtypes if item[1].startswith(('string'))]\n","df.agg(*(F.countDistinct(F.col(c)).alias(c) for c in columnCat)).show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+----+---+------+-----+--------+\n","|Name|Sex|Ticket|Cabin|Embarked|\n","+----+---+------+-----+--------+\n","| 891|  2|   681|  147|       3|\n","+----+---+------+-----+--------+\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qPEklxePaarN"},"source":["## Check imbalanced classes?"]},{"cell_type":"code","metadata":{"id":"v67ScxDjaarN","outputId":"062e2720-485e-4a88-ef60-2badf68495c3"},"source":["df.groupBy(\"Survived\").count().show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+--------+-----+\n","|Survived|count|\n","+--------+-----+\n","|       1|  342|\n","|       0|  549|\n","+--------+-----+\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"W1lA03SjaarN"},"source":["# Split trainning set and validation set"]},{"cell_type":"code","metadata":{"id":"wd7dnPL7aarN","outputId":"a272555b-2328-4947-e36e-e97b01fab3b0"},"source":["train = df.sampleBy(\"Survived\", fractions={0: 0.7, 1: 0.7}, seed=42)\n","val = df.subtract(train)\n","train.groupBy(\"Survived\").count().show()\n","val.groupBy(\"Survived\").count().show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+--------+-----+\n","|Survived|count|\n","+--------+-----+\n","|       1|  241|\n","|       0|  418|\n","+--------+-----+\n","\n","+--------+-----+\n","|Survived|count|\n","+--------+-----+\n","|       1|  101|\n","|       0|  131|\n","+--------+-----+\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"co52UkV-aarO"},"source":["# Feature engineering"]},{"cell_type":"markdown","metadata":{"id":"868u41FkaarO"},"source":["Extract title from `Name`, `Cabin`. Add  `Family_Size`, `Fare_Per_Person` and drop unused columns: `PassengerId`, `Ticket`, `SibSp`, `Parch`"]},{"cell_type":"code","metadata":{"id":"nYTP02zCaarO"},"source":["class ColAdderDropper(Transformer, Estimator):\n","    def __init__(self, num_top_titles=1):\n","        self.num_top_titles = num_top_titles\n","        \n","    def _fit(self, X_df):\n","        title_col = X_df.withColumn('Name', F.regexp_extract(F.col('Name'), r'([a-zA-z]+)\\.',1))\n","        self.title_counts_ = title_col.groupBy('Name').count().orderBy('count', ascending=False)\n","        titles = self.title_counts_.select('Name').collect()\n","        self.top_titles_ = titles[:max(1, min(self.num_top_titles, len(titles)))]\n","        self.top_titles_ = [ row.Name for row in self.top_titles_]\n","\n","    def _transform(self, X_df):\n","        top_titles_ = self.top_titles_\n","        res = X_df.withColumn('Name', F.regexp_extract(F.col('Name'), r'([a-zA-z]+)\\.',1))\n","        fn = F.udf(lambda x: x if x in top_titles_ else 'Others')\n","        res = res.withColumn('Name', fn(res['Name']))\n","        \n","        fn_1 = F.udf(lambda x: x[0] if x != None else 'Unknown')\n","        res = res.withColumn('Cabin', fn_1(res['Cabin']))    \n","        \n","        res = res.withColumn('Family_Size', sum(res[col] for col in ['SibSp','Parch']))\n","        \n","        res = res.withColumn('Fare_Per_Person',res['Fare'] / (res['Family_Size']+1))\n","                \n","        res = res.drop('PassengerId','Ticket','SibSp','Parch')\n","        return res"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6kgh8cg1aarP","outputId":"7a6b19ed-2b48-48a1-aac9-1b311c0bac40"},"source":["col_adderdropper = ColAdderDropper(num_top_titles=5)\n","col_adderdropper.fit(df)\n","col_adderdropper.transform(df).show(5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+--------+------+----+------+----+-------+-------+--------+-----------+---------------+\n","|Survived|Pclass|Name|   Sex| Age|   Fare|  Cabin|Embarked|Family_Size|Fare_Per_Person|\n","+--------+------+----+------+----+-------+-------+--------+-----------+---------------+\n","|       0|     3|  Mr|  male|22.0|   7.25|Unknown|       S|          1|          3.625|\n","|       1|     1| Mrs|female|38.0|71.2833|      C|       C|          1|       35.64165|\n","|       1|     3|Miss|female|26.0|  7.925|Unknown|       S|          0|          7.925|\n","|       1|     1| Mrs|female|35.0|   53.1|      C|       S|          1|          26.55|\n","|       0|     3|  Mr|  male|35.0|   8.05|Unknown|       S|          0|           8.05|\n","+--------+------+----+------+----+-------+-------+--------+-----------+---------------+\n","only showing top 5 rows\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ArLI5mj5aarP"},"source":["## Handling numerical data"]},{"cell_type":"code","metadata":{"id":"rLgSlrO6aarP"},"source":["num_cols = ['Age', 'Family_Size', 'Fare_Per_Person','Fare']\n","imputer_num = Imputer(strategy='mean', inputCols=num_cols, outputCols=[c for c in num_cols])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"31ktF62maarQ"},"source":["## Handling categorical data"]},{"cell_type":"code","metadata":{"id":"eFlvqjG0aarQ"},"source":["unorder_cate_cols = ['Sex', 'Embarked', 'Name','Cabin']\n","label_cate_cols = ['Sex_string_encoded', 'Embarked_string_encoded', 'Name_string_encoded','Cabin_string_encoded']\n","onehot_cate_cols = ['Sex_one_hot', 'Embarked_one_hot', 'Name_one_hot','Cabin_one_hot']\n","order_cate_cols = ['Pclass']\n","\n","stage_string = [StringIndexer(inputCol= c, outputCol= c+\"_string_encoded\", handleInvalid=\"keep\") for c in unorder_cate_cols]\n","\n","imputer_cate = Imputer(strategy='mode', inputCols=label_cate_cols+order_cate_cols, \\\n","                       outputCols=[c for c in label_cate_cols+order_cate_cols])\n","\n","stage_one_hot = [OneHotEncoder(inputCol= c+\"_string_encoded\", outputCol= c+ \"_one_hot\") for c in unorder_cate_cols]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8pB68n2taarR"},"source":["Drop unused colums after Handling categorical data"]},{"cell_type":"code","metadata":{"id":"5eGUSLocaarR"},"source":["class ColDropper(Transformer):\n","    def _transform(self, X_df):   \n","        res = X_df\n","        res = res.drop('Sex', 'Embarked', 'Name','Cabin', 'Sex_string_encoded', 'Embarked_string_encoded', 'Name_string_encoded','Cabin_string_encoded')\n","        return res\n","col_dropper = ColDropper()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jLcFsg6OaarS"},"source":["## Put them together"]},{"cell_type":"code","metadata":{"id":"emmY2p6raarT"},"source":["vector_assembler = VectorAssembler(inputCols = num_cols+order_cate_cols+onehot_cate_cols, outputCol= \"features\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xqjsbuHEaarU"},"source":["## Modeling "]},{"cell_type":"code","metadata":{"id":"rCeNKaMRaarU"},"source":["rf = RandomForestClassifier(labelCol = \"Survived\", featuresCol = \"features\", numTrees=250, subsamplingRate=0.5,\\\n","                            minInstancesPerNode=3, maxDepth=4, seed=42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q0jdUMCwaarU"},"source":["## Create full pipeline"]},{"cell_type":"code","metadata":{"id":"5g8jpG9IaarU"},"source":["stage = [col_adderdropper] + [imputer_num] + stage_string + [imputer_cate]\\\n","+ stage_one_hot + [col_dropper] + [vector_assembler] + [rf]\n"," \n","full_pipeline = Pipeline(stages=stage)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pjFcFV97aarU"},"source":["## Evaluation"]},{"cell_type":"code","metadata":{"id":"sXFAsBCgaarV","outputId":"168f9eaa-d3f3-49fa-ad8d-f14321d4fb29"},"source":["model = full_pipeline.fit(train)\n","y_train =  model.transform(train)\n","y_val = model.transform(val)\n","\n","evaluator= BCE(labelCol = \"Survived\", rawPredictionCol=\"probability\", metricName= \"areaUnderROC\")\n","train_accuracy = evaluator.evaluate(y_train)\n","val_accuracy = evaluator.evaluate(y_val)\n","\n","print(f\"Train accuracy : {train_accuracy}\")\n","print(f\"Validation accuracy : {val_accuracy}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train accuracy : 0.8714387817903864\n","Validation accuracy : 0.9064696545990486\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q6xQsdpiaarV"},"source":["test = spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(\"Data/test.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2shMqXaLaarV"},"source":["y_test = model.transform(test)\n","\n","PassengerId = test.select(\"PassengerId\")\n","Survived = y_test.select(\"prediction\")\n","Survived = Survived.withColumn(\"prediction\", F.round(Survived[\"prediction\"]).cast('integer'))\n","\n","PassengerId = PassengerId.withColumn(\"id\", F.monotonically_increasing_id())\n","Survived = Survived.withColumn(\"id\", F.monotonically_increasing_id())\n","\n","result = PassengerId.join(Survived, \"id\", \"outer\").drop(\"id\").orderBy(\"PassengerId\")\n","result = result.withColumnRenamed(\"prediction\", \"Survived\")\n","\n","result.toPandas().to_csv('Data/submission.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aTccgEbyaarV"},"source":["Score on Kaggle: 0.79186 (top 8%)"]},{"cell_type":"code","metadata":{"id":"4JmD-Mi-aarW"},"source":["spark.stop()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iwHB6DGLaarX"},"source":["# Reference"]},{"cell_type":"markdown","metadata":{"id":"rsDMCrlRaarX"},"source":["[Feature engineering](https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/)"]}]}